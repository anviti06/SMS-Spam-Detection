{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anviti/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.tree import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "porter = nltk.PorterStemmer()\n",
    "    \n",
    "def trainmodel():\n",
    "    #1.Text Processing\n",
    "    df = pd.read_table('SMSSpamCollection.txt', header=None)\n",
    "    y = df[0]\n",
    "    #print(df.head())\n",
    "    #df.info()\n",
    "    #Label encoders -converting Spam as 1 and Ham as 0\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    #replacing SMS Data into original place\n",
    "    raw_text = df[1]\n",
    "    #2. Text Processing\n",
    "\n",
    "    processed = raw_text.str.replace(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b',\n",
    "                                     'emailaddr')\n",
    "    processed = processed.str.replace(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)',\n",
    "                                      'httpaddr')\n",
    "    processed = processed.str.replace(r'£|\\$', 'moneysymb')    \n",
    "    processed = processed.str.replace(\n",
    "        r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
    "        'phonenumbr')    \n",
    "    processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "    processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "    processed = processed.str.replace(r'\\s+', ' ')\n",
    "    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "    processed = processed.str.lower()\n",
    "\n",
    "    #removing stop words\n",
    "    \n",
    "    processed = processed.apply(lambda x: ' '.join(\n",
    "        term for term in x.split() if term not in set(stop_words))\n",
    "    )\n",
    "\n",
    "    #stemming\n",
    "    processed = processed.apply(lambda x: ' '.join(\n",
    "        porter.stem(term) for term in x.split())\n",
    "    )\n",
    "\n",
    "    #3. Feature ENgineering\n",
    "    #3.1 Tokenization - using tf-idf static to create a matrix with each row representing training example and each col \n",
    "    #    representing the tf-idf value of nth gram word(here we use 1 gram and 2 gram , i.e taking 1 work at a time , \n",
    "    #    and taking two words at a time). This is also called vectorization\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    X_ngrams = vectorizer.fit_transform(processed)\n",
    "    #X_ngrams.shape #pretty big matrix with 36348 cols showing 1gram or 2-gram words\n",
    "    #4. Training and evaluating model\n",
    "    #SVM: finds a hyperplane that deferentiates these two classes\n",
    "\n",
    "    #Splitting into and Testing Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_ngrams,\n",
    "        y_enc,\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=y_enc\n",
    "    )\n",
    "    \n",
    "    classifiers =[LinearSVC(loss='hinge'), RandomForestClassifier(),LogisticRegression(penalty='l2'),MultinomialNB() ]\n",
    "\n",
    "    #1. SVM Classifier\n",
    "    mx = 0\n",
    "    for i in classifiers:\n",
    "        i.fit(X_train, y_train)\n",
    "        y_pred = i.predict(X_test)\n",
    "        score = metrics.f1_score(y_test, y_pred)\n",
    "        if(score > mx):\n",
    "            mx = score\n",
    "            clf = i\n",
    "        print (\"Data has been trained with \" ,i , \" having score : \" ,score,end='')\n",
    "        print('')\n",
    "        \n",
    "    \n",
    "    return clf, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been trained with  LinearSVC(loss='hinge')  having score :  0.9289099526066351\n",
      "Data has been trained with  RandomForestClassifier()  having score :  0.9073170731707317\n",
      "Data has been trained with  LogisticRegression()  having score :  0.8042328042328042\n",
      "Data has been trained with  MultinomialNB()  having score :  0.8363636363636363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LinearSVC(loss='hinge'), TfidfVectorizer(ngram_range=(1, 2)))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(messy_string):\n",
    "    assert(type(messy_string) == str)\n",
    "    cleaned = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'emailaddr', messy_string)\n",
    "    cleaned = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'httpaddr',\n",
    "                     cleaned)\n",
    "    cleaned = re.sub(r'£|\\$', 'moneysymb', cleaned)\n",
    "    cleaned = re.sub(\n",
    "        r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
    "        'phonenumbr', cleaned)\n",
    "    cleaned = re.sub(r'\\d+(\\.\\d+)?', 'numbr', cleaned)\n",
    "    cleaned = re.sub(r'[^\\w\\d\\s]', ' ', cleaned)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "    cleaned = re.sub(r'^\\s+|\\s+?$', '', cleaned.lower())\n",
    "    return ' '.join(\n",
    "        porter.stem(term) \n",
    "        for term in cleaned.split()\n",
    "        if term not in set(stop_words)\n",
    "    )\n",
    "\n",
    "def spam_filter(message):\n",
    "    clf, vectorizer = trainmodel()\n",
    "    if clf.predict(vectorizer.transform([preprocess_text(message)])):\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'not spam'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been trained with  LinearSVC(loss='hinge')  having score :  0.9289099526066351\n",
      "Data has been trained with  RandomForestClassifier()  having score :  0.9046454767726161\n",
      "Data has been trained with  LogisticRegression()  having score :  0.8042328042328042\n",
      "Data has been trained with  MultinomialNB()  having score :  0.8363636363636363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'not spam'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_filter('Ohhh, but those are the best kind of foods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
